# -*- coding: utf-8 -*-
"""E8day11.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1H3YWpfFPt2HMcRxjcgepslpacyMHC76J
"""

## This script demonstrates how to tokenize text into words using NLTK (Natural Language Toolkit).

import nltk
from nltk.tokenize import word_tokenize

# Download tokenizer models
nltk.download('punkt')
nltk.download('punkt_tab') # Download the required resource

# Sample text
text = "Hello there! How are you doing today?"

# Tokenize into words
tokens = word_tokenize(text)
print("Word Tokens:", tokens)

# ✅ Install necessary packages
!pip install transformers torch --quiet

# ✅ Import libraries
import torch
from transformers import pipeline

# ✅ Load the pre-trained sentiment analysis pipeline
sentiment_pipeline = pipeline("sentiment-analysis")

# ✅ Define function for analyzing sentiment
def analyze_sentiment(text):
    """
    Analyzes the sentiment of the given text and returns the sentiment label and score.
    """
    result = sentiment_pipeline(text)[0]
    return result

# ✅ Install necessary packages
!pip install transformers torch --quiet

# ✅ Import libraries
import torch
from transformers import pipeline

# ✅ Load the pre-trained sentiment analysis pipeline
sentiment_pipeline = pipeline("sentiment-analysis")

# ✅ Define function for analyzing sentiment
def analyze_sentiment(text):
    """
    Analyzes the sentiment of the given text and returns the sentiment label and score.
    """
    result = sentiment_pipeline(text)[0]
    return result

# ✅ Sample texts for testing
sample_texts = [
    "I love this product! It works great and has changed my life for the better.",
    "This is the worst experience I've ever had. I'm very disappointed.",
    "The movie was okay, but it could have been better.",
    "I'm so happy with the service I received!",
    "This is absolutely terrible. I will never come back here again."
]

# ✅ Run sentiment analysis on each sentence
for text in sample_texts:
    sentiment_result = analyze_sentiment(text)
    print(f"Text: {text}")
    print(f"Sentiment: {sentiment_result['label']}, Score: {sentiment_result['score']:.2f}\n")

import numpy as np

# 1. Generate Input RGB Values
np.random.seed(42) # for reproducibility
input_rgb = np.random.rand(10, 10, 3) # 10x10 image with 3 color channels

# 2. Flatten the RGB Channels
height, width, channels = input_rgb.shape
flattened_rgb = input_rgb.reshape(height * width, channels)

# Define dimensions (example values)
input_dim = channels
hidden_dim = 64 # Example hidden dimension for Q, K, V

# Initialize random weights for Q, K, V
W_q = np.random.rand(input_dim, hidden_dim)
W_k = np.random.rand(input_dim, hidden_dim)
W_v = np.random.rand(input_dim, hidden_dim)

# Compute Q, K, V
Q = np.dot(flattened_rgb, W_q)
K = np.dot(flattened_rgb, W_k)
V = np.dot(flattened_rgb, W_v)

# 3. Compute Attention Weights
# Scaled dot-product attention
attention_scores = np.dot(Q, K.T) / np.sqrt(hidden_dim)

# 4. Apply Softmax
def softmax(x):
    e_x = np.exp(x - np.max(x, axis=-1, keepdims=True))
    return e_x / e_x.sum(axis=-1, keepdims=True)

attention_weights = softmax(attention_scores)

# 5. Compute Weighted Average
attention_output = np.dot(attention_weights, V)

# 6. Reconstruct Output
# Learnable output weight and bias
W_o = np.random.rand(hidden_dim, channels)
b_o = np.random.rand(channels)

# Apply output weight and add bias (simple linear transformation)
output_transformed = np.dot(attention_output, W_o) + b_o

# Add skip connection (adding original pixel information)
output_rgb_flat = output_transformed + flattened_rgb

# Reshape back to original image dimensions
output_rgb = output_rgb_flat.reshape(height, width, channels)

print("Original RGB shape:", input_rgb.shape)
print("Flattened RGB shape:", flattened_rgb.shape)
print("Q shape:", Q.shape)
print("K shape:", K.shape)
print("V shape:", V.shape)
print("Attention scores shape:", attention_scores.shape)
print("Attention weights shape:", attention_weights.shape)
print("Attention output shape:", attention_output.shape)
print("Output RGB shape:", output_rgb.shape)

# # This script implements a simple chatbot using Natural Language Processing (NLP) techniques.
# It uses NLTK for text processing and TF-IDF for similarity matching.
# Program: Simple NLP Chatbot
# Description: This program implements a simple chatbot using Natural Language Processing (NLP) techniques.
import nltk
import numpy as np
import random
import string
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Download required NLTK data
nltk.download('punkt')      # for tokenization
nltk.download('wordnet')    # for lemmatization
nltk.download('omw-1.4')

# Sample corpus (you can replace this with file read or a bigger dataset)
corpus = """
Hello, how can I help you?
I can assist with your questions.
What is Natural Language Processing?
Natural Language Processing is a branch of artificial intelligence.
It deals with the interaction between computers and humans using natural language.
What is your name?
I am a chatbot created using Python and NLP.
Thank you
You are welcome
Goodbye
"""

# Tokenization
sent_tokens = nltk.sent_tokenize(corpus)  # Convert text into sentences

# Lemmatization function
lemmer = nltk.stem.WordNetLemmatizer()
def LemTokens(tokens):
    return [lemmer.lemmatize(token.lower()) for token in tokens if token not in string.punctuation]

# Preprocessing function
def preprocess_text(text):
    return LemTokens(nltk.word_tokenize(text.lower()))

# Greeting inputs/outputs
GREETING_INPUTS = ("hello", "hi", "greetings", "sup", "what's up", "hey")
GREETING_RESPONSES = ["Hi!", "Hey!", "Hello there!", "Hello!", "I'm glad you're talking to me!"]

def greeting(sentence):
    for word in sentence.split():
        if word.lower() in GREETING_INPUTS:
            return random.choice(GREETING_RESPONSES)

# Chatbot response generator
def generate_response(user_input):
    sent_tokens.append(user_input)  # Add user input to the sentence list
    vectorizer = TfidfVectorizer(tokenizer=preprocess_text, stop_words='english')
    tfidf = vectorizer.fit_transform(sent_tokens)  # TF-IDF matrix
    vals = cosine_similarity(tfidf[-1], tfidf)  # Compare last sentence (user input) to all
    idx = vals.argsort()[0][-2]  # Best match index
    flat = vals.flatten()
    flat.sort()
    score = flat[-2]

    if score == 0:
        response = "I'm sorry, I don't understand that."
    else:
        response = sent_tokens[idx]

    sent_tokens.pop()  # Remove the user input
    return response

# Main Chat Loop
print("NLPBot: Hello! I am an NLP chatbot. Type 'bye' to exit.")

while True:
    user_input = input("You: ").strip()
    if user_input.lower() in ['bye', 'exit', 'quit']:
        print("NLPBot: Goodbye! Take care.")
        break
    elif user_input.lower() in ['thanks', 'thank you']:
        print("NLPBot: You're welcome!")
    elif greeting(user_input) is not None:
        print(f"NLPBot: {greeting(user_input)}")
    else:
        print("NLPBot:", generate_response(user_input))